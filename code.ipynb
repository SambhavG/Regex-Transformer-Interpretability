{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define constants\n",
    "MAX_LENGTH = 50\n",
    "VALID_CHARACTERS = [\"s\", \"a\", \"b\", \"e\", \"p\"]\n",
    "MAIN_CHARACTERS = [\"a\", \"b\"]\n",
    "START_TOKEN = \"s\"\n",
    "END_TOKEN = \"e\"\n",
    "PADDING_TOKEN = \"p\"\n",
    "VALID_RATIO = 0.5  # Half of the dataset should be valid a*b* strings\n",
    "\n",
    "\n",
    "# Function to generate valid a*b* strings\n",
    "def generate_valid_string():\n",
    "    num_a = random.randint(0, MAX_LENGTH - 2)\n",
    "    num_b = random.randint(0, MAX_LENGTH - 2 - num_a)\n",
    "    valid_str = \"a\" * num_a + \"b\" * num_b\n",
    "    return (\n",
    "        START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        + PADDING_TOKEN * (MAX_LENGTH - len(valid_str) - 2)\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to generate invalid strings\n",
    "def generate_invalid_string():\n",
    "    length = random.randint(1, MAX_LENGTH - 2)\n",
    "    if length == 1:\n",
    "        return START_TOKEN + \"ba\" + END_TOKEN + PADDING_TOKEN * (MAX_LENGTH - 2)\n",
    "    while True:\n",
    "        # Random string of a's and b's which isn't a valid a*b* string\n",
    "        invalid_str = \"\".join(random.choices(MAIN_CHARACTERS, k=length))\n",
    "        if \"ba\" in invalid_str:\n",
    "            break\n",
    "    return (\n",
    "        START_TOKEN\n",
    "        + invalid_str\n",
    "        + END_TOKEN\n",
    "        + PADDING_TOKEN * (MAX_LENGTH - len(invalid_str) - 2)\n",
    "    )\n",
    "\n",
    "\n",
    "# Generate dataset\n",
    "dataset = []\n",
    "num_samples = 10000  # Total number of samples\n",
    "num_valid_samples = 15000  # int(VALID_RATIO * num_samples)\n",
    "num_invalid_samples = 1500  # num_samples - num_valid_samples\n",
    "\n",
    "for _ in range(num_valid_samples):\n",
    "    while True:\n",
    "        x = generate_valid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        dataset.append((x, 1))\n",
    "        break\n",
    "\n",
    "for _ in range(num_invalid_samples):\n",
    "    while True:\n",
    "        x = generate_invalid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        dataset.append((x, 0))\n",
    "        break\n",
    "\n",
    "# Remove all duplicates\n",
    "dataset = list(set(dataset))\n",
    "\n",
    "# Write to file\n",
    "with open(\"dataset.txt\", \"w\") as f:\n",
    "    for data, label in dataset:\n",
    "        f.write(f\"{data} {label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.645404577255249\n",
      "Accuracy: 0.6271896420411271\n",
      "Epoch 2/30, Loss: 0.5931392312049866\n",
      "Accuracy: 0.7010662604722011\n",
      "Epoch 3/30, Loss: 0.61623615026474\n",
      "Accuracy: 0.7098248286367098\n",
      "Epoch 4/30, Loss: 0.4925661087036133\n",
      "Accuracy: 0.7402894135567403\n",
      "Epoch 5/30, Loss: 0.4830002784729004\n",
      "Accuracy: 0.7635186595582635\n",
      "Epoch 6/30, Loss: 0.5012676119804382\n",
      "Accuracy: 0.7924600152322925\n",
      "Epoch 7/30, Loss: 0.45602673292160034\n",
      "Accuracy: 0.801980198019802\n",
      "Epoch 8/30, Loss: 0.521774172782898\n",
      "Accuracy: 0.8111195734958111\n",
      "Epoch 9/30, Loss: 0.3749580681324005\n",
      "Accuracy: 0.8164508758568164\n",
      "Epoch 10/30, Loss: 0.4207557439804077\n",
      "Accuracy: 0.8229246001523229\n",
      "Epoch 11/30, Loss: 0.39253461360931396\n",
      "Accuracy: 0.8282559025133283\n",
      "Epoch 12/30, Loss: 0.35285770893096924\n",
      "Accuracy: 0.8305407463823306\n",
      "Epoch 13/30, Loss: 0.3151388466358185\n",
      "Accuracy: 0.8358720487433359\n",
      "Epoch 14/30, Loss: 0.4389675557613373\n",
      "Accuracy: 0.8408225437928408\n",
      "Epoch 15/30, Loss: 0.3898017406463623\n",
      "Accuracy: 0.8465346534653465\n",
      "Epoch 16/30, Loss: 0.44383639097213745\n",
      "Accuracy: 0.84996191926885\n",
      "Epoch 17/30, Loss: 0.41312524676322937\n",
      "Accuracy: 0.8514851485148515\n",
      "Epoch 18/30, Loss: 0.3084469437599182\n",
      "Accuracy: 0.8545316070068545\n",
      "Epoch 19/30, Loss: 0.49521297216415405\n",
      "Accuracy: 0.8552932216298553\n",
      "Epoch 20/30, Loss: 0.42098763585090637\n",
      "Accuracy: 0.8526275704493527\n",
      "Epoch 21/30, Loss: 0.505305826663971\n",
      "Accuracy: 0.8602437166793603\n",
      "Epoch 22/30, Loss: 0.33076804876327515\n",
      "Accuracy: 0.8629093678598629\n",
      "Epoch 23/30, Loss: 0.4292489290237427\n",
      "Accuracy: 0.8587204874333587\n",
      "Epoch 24/30, Loss: 0.5100225806236267\n",
      "Accuracy: 0.8552932216298553\n",
      "Epoch 25/30, Loss: 0.35586515069007874\n",
      "Accuracy: 0.8556740289413557\n",
      "Epoch 26/30, Loss: 0.3238961398601532\n",
      "Accuracy: 0.8602437166793603\n",
      "Epoch 27/30, Loss: 0.42551150918006897\n",
      "Accuracy: 0.861005331302361\n",
      "Epoch 28/30, Loss: 0.46683308482170105\n",
      "Accuracy: 0.854912414318355\n",
      "Epoch 29/30, Loss: 0.24269121885299683\n",
      "Accuracy: 0.8571972581873571\n",
      "Epoch 30/30, Loss: 0.5060492157936096\n",
      "Accuracy: 0.8651942117288652\n",
      "Epoch 1/30, Loss: 0.3607003092765808\n",
      "Accuracy: 0.8648134044173648\n",
      "Epoch 2/30, Loss: 0.4726361036300659\n",
      "Accuracy: 0.8606245239908606\n",
      "Epoch 3/30, Loss: 0.6077157258987427\n",
      "Accuracy: 0.8594821020563594\n",
      "Epoch 4/30, Loss: 0.4213886260986328\n",
      "Accuracy: 0.857958872810358\n",
      "Epoch 5/30, Loss: 0.282149076461792\n",
      "Accuracy: 0.8591012947448591\n",
      "Epoch 6/30, Loss: 0.29811087250709534\n",
      "Accuracy: 0.8591012947448591\n",
      "Epoch 7/30, Loss: 0.24162425100803375\n",
      "Accuracy: 0.8583396801218584\n",
      "Epoch 8/30, Loss: 0.4250212609767914\n",
      "Accuracy: 0.8613861386138614\n",
      "Epoch 9/30, Loss: 0.4001212418079376\n",
      "Accuracy: 0.8629093678598629\n",
      "Epoch 10/30, Loss: 0.5136442184448242\n",
      "Accuracy: 0.8617669459253617\n",
      "Epoch 11/30, Loss: 0.3188765048980713\n",
      "Accuracy: 0.8625285605483626\n",
      "Epoch 12/30, Loss: 0.3911343514919281\n",
      "Accuracy: 0.861005331302361\n",
      "Epoch 13/30, Loss: 0.415478378534317\n",
      "Accuracy: 0.8602437166793603\n",
      "Epoch 14/30, Loss: 0.5054507255554199\n",
      "Accuracy: 0.861005331302361\n",
      "Epoch 15/30, Loss: 0.36672064661979675\n",
      "Accuracy: 0.8617669459253617\n",
      "Epoch 16/30, Loss: 0.4597167670726776\n",
      "Accuracy: 0.8625285605483626\n",
      "Epoch 17/30, Loss: 0.3961889147758484\n",
      "Accuracy: 0.8613861386138614\n",
      "Epoch 18/30, Loss: 0.3235830068588257\n",
      "Accuracy: 0.861005331302361\n",
      "Epoch 19/30, Loss: 0.5398224592208862\n",
      "Accuracy: 0.861005331302361\n",
      "Epoch 20/30, Loss: 0.3930172324180603\n",
      "Accuracy: 0.8613861386138614\n",
      "Epoch 21/30, Loss: 0.35503873229026794\n",
      "Accuracy: 0.8621477532368621\n",
      "Epoch 22/30, Loss: 0.33547407388687134\n",
      "Accuracy: 0.8625285605483626\n",
      "Epoch 23/30, Loss: 0.3370097279548645\n",
      "Accuracy: 0.8621477532368621\n",
      "Epoch 24/30, Loss: 0.3805837631225586\n",
      "Accuracy: 0.8621477532368621\n",
      "Epoch 25/30, Loss: 0.2656356990337372\n",
      "Accuracy: 0.8617669459253617\n",
      "Epoch 26/30, Loss: 0.33399727940559387\n",
      "Accuracy: 0.8613861386138614\n",
      "Epoch 27/30, Loss: 0.47642919421195984\n",
      "Accuracy: 0.8629093678598629\n",
      "Epoch 28/30, Loss: 0.3565469980239868\n",
      "Accuracy: 0.8632901751713633\n",
      "Epoch 29/30, Loss: 0.44307535886764526\n",
      "Accuracy: 0.8625285605483626\n",
      "Epoch 30/30, Loss: 0.41178080439567566\n",
      "Accuracy: 0.8632901751713633\n",
      "Accuracy: 0.8629093678598629\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define constants for model\n",
    "VOCAB_SIZE = len(VALID_CHARACTERS)\n",
    "EMBEDDING_DIM = 6\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 1\n",
    "HIDDEN_DIM = 2\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 30\n",
    "\n",
    "# Mapping characters to indices\n",
    "char_to_index = {ch: idx for idx, ch in enumerate(VALID_CHARACTERS)}\n",
    "\n",
    "# Custom dataset class\n",
    "class StringDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(\" \")\n",
    "                self.data.append(parts[0])\n",
    "                self.labels.append(int(parts[1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        string = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoded = self.encode_string(string)\n",
    "        return torch.tensor(encoded, dtype=torch.long), torch.tensor(\n",
    "            label, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "    def encode_string(self, string):\n",
    "        return [char_to_index[char] for char in string]\n",
    "\n",
    "\n",
    "# Transformer model\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_heads, hidden_dim, num_layers):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_encoder = nn.Parameter(torch.zeros(1, MAX_LENGTH, embedding_dim))\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            embedding_dim, num_heads, hidden_dim\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(MAX_LENGTH * embedding_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.pos_encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "# Prepare dataset and dataloader\n",
    "dataset = StringDataset(\"dataset.txt\")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = TransformerClassifier(\n",
    "    VOCAB_SIZE, EMBEDDING_DIM, NUM_HEADS, HIDDEN_DIM, NUM_LAYERS\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cpu\" and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "        loss = criterion(outputs.squeeze(), labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item()}\")\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        outputs = model(inputs.to(device))\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.squeeze().to(device) == labels.to(device)).sum().item()\n",
    "    print(f\"Accuracy: {correct/total}\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "        loss = criterion(outputs.squeeze(), labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item()}\")\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        outputs = model(inputs.to(device))\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.squeeze().to(device) == labels.to(device)).sum().item()\n",
    "    print(f\"Accuracy: {correct/total}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"transformer_model.pth\")\n",
    "\n",
    "# Print accuracy of the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for inputs, labels in dataloader:\n",
    "    outputs = model(inputs.to(device))\n",
    "    predicted = torch.round(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.squeeze().to(device) == labels.to(device)).sum().item()\n",
    "print(f\"Accuracy: {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 examples which are wrongly classified\n",
      "saaaabbbbepppppppppppppppppppppppppppppppppppppppp 1.0 0.0\n",
      "sabbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbepppppppppppppp 1.0 0.0\n",
      "sbbbbbbbbbbbbbbbbbbbbepppppppppppppppppppppppppppp 1.0 0.0\n",
      "saabbaabbaabbbbbbabbbbbabaaaabbbbbaabepppppppppppp 0.0 1.0\n",
      "saaaabababbabbaaeppppppppppppppppppppppppppppppppp 0.0 1.0\n",
      "saaabbabaabbaaaabbbaababbabbeppppppppppppppppppppp 0.0 1.0\n",
      "saaabbbbbbbbeppppppppppppppppppppppppppppppppppppp 1.0 0.0\n",
      "saabbbbbbbbbbbbbbbbbeppppppppppppppppppppppppppppp 1.0 0.0\n",
      "sababaabbaabbababbbbaabbbabaaabbbbbbeppppppppppppp 0.0 1.0\n",
      "saaaaaaabbbbbabaaabbaabaaabaeppppppppppppppppppppp 0.0 1.0\n",
      "saaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaabbepppp 1.0 0.0\n",
      "saaaabbbbabbabbbabababbbababaaaaaepppppppppppppppp 0.0 1.0\n",
      "sbaaaababaaaabbababbaababbbbbabbbbbabaabbaaabbbbep 0.0 1.0\n",
      "saaaaabbaaaabbabbbabaaaabaeppppppppppppppppppppppp 0.0 1.0\n",
      "sabbbbbbbbbbbbbbbbbbbbbbeppppppppppppppppppppppppp 1.0 0.0\n",
      "saaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaeppppppppppp 1.0 0.0\n",
      "saaabbbbbbbepppppppppppppppppppppppppppppppppppppp 1.0 0.0\n",
      "saaaaaaaabaaaabbabbbbbbabbaababbeppppppppppppppppp 0.0 1.0\n",
      "saaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaabbeppp 1.0 0.0\n",
      "saabaaabbbabbbaaabaaabbababaabbbabbabbabaaaabbbbbe 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print 20 examples which are wrongly classified\n",
    "print(\"20 examples which are wrongly classified\")\n",
    "count = 0\n",
    "for inputs, labels in dataloader:\n",
    "    outputs = model(inputs.to(device))\n",
    "    predicted = torch.round(outputs)\n",
    "    for i in range(len(predicted)):\n",
    "        if count == 20:\n",
    "            break\n",
    "        if predicted[i] != labels[i]:\n",
    "            # Convert back to string of a's and b's\n",
    "            string = \"\".join([VALID_CHARACTERS[int(idx)] for idx in inputs[i]])\n",
    "            print(string, labels[i].item(), predicted[i].item())\n",
    "            count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
