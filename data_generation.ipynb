{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:42<00:00, 1182.47it/s]\n",
      "100%|██████████| 50000/50000 [00:40<00:00, 1225.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(valid_dataset): 50000\n",
      "len(invalid_dataset): 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:05<00:00, 2671.25it/s]\n",
      "100%|██████████| 15000/15000 [00:04<00:00, 3103.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ood_valid_dataset):  15000 len(ood_invalid_dataset):  15000\n",
      "len(train_dataset):  80000\n",
      "len(test_dataset):  20000\n",
      "len(ood_dataset):  30000\n",
      "/orion/u/yrichard/n/key_trials/test_aaaa_200_400\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Define constants\n",
    "MAX_LENGTH = 200\n",
    "OOD_MAX_LENGTH = 400\n",
    "VALID_CHARACTERS = [\"s\", \"a\", \"b\", \"c\", 'd', 'f', 'g', 'x', 'y', 'z', \"e\", \"p\"]\n",
    "MAIN_CHARACTERS = [\"a\", \"b\", \"c\", 'd', 'f', 'g', 'x', 'y', 'z']\n",
    "START_TOKEN = \"s\"\n",
    "END_TOKEN = \"e\"\n",
    "PADDING_TOKEN = \"p\"\n",
    "VALID_RATIO = 0.5  # Half of the dataset should be valid a*b* strings\n",
    "\n",
    "\n",
    "# Function to generate valid a*b* strings\n",
    "def generate_valid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens\n",
    "    min_length = max(min_length, 2)\n",
    "    \n",
    "    while True:\n",
    "        # Generate the string with 'a's and 'b's while ensuring no three consecutive 'a's\n",
    "        valid_str = \"\"\n",
    "        valid_max = random.randint(0, max_length - 2)\n",
    "        while len(valid_str) < valid_max:\n",
    "            next_char = random.choice(['a', 'b'])\n",
    "            if next_char == 'a' and valid_str.endswith('aaa'):\n",
    "                next_char = random.choice(['b'])\n",
    "            valid_str += next_char\n",
    "            \n",
    "        \n",
    "        # Check if the length of the valid_str is within the desired range\n",
    "        if len(valid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    # num_p = random.randint(0, max_length - len(valid_str) - 2)\n",
    "    return (\n",
    "        # PADDING_TOKEN * num_p +\n",
    "        START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        # + PADDING_TOKEN * ((max_length - len(valid_str) - 2) - num_p)\n",
    "        + PADDING_TOKEN * ((max_length - len(valid_str) - 2))\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Function to generate invalid strings\n",
    "def generate_invalid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens    \n",
    "    while True:\n",
    "        # Generate the base string with random 'a's and 'b's\n",
    "        # num_invalids = int((max_length - min_length) * 0.05)\n",
    "        num_invalids = 3\n",
    "\n",
    "\n",
    "        base_str_length = random.randint(0, max_length - 2 - num_invalids*4)  # Account for START, END tokens, and at least three 'a's\n",
    "        base_str = ''.join(random.choice(['a', 'b']) for _ in range(base_str_length))\n",
    "        invalid_str = base_str\n",
    "        \n",
    "        # Insert 'aaa' at a random position\n",
    "        for i in range(num_invalids):\n",
    "            insert_pos = random.randint(0, len(invalid_str))\n",
    "            string = random.choice([\"aaaa\"])\n",
    "            invalid_str = invalid_str[:insert_pos] + string + invalid_str[insert_pos:]\n",
    "            # if base_str_length % 2 == 0:\n",
    "            #     insert_pos = random.randint(0, len(invalid_str))\n",
    "            #     string = random.choice([\"a\"])\n",
    "            #     invalid_str = invalid_str[:insert_pos] + string + invalid_str[insert_pos:]\n",
    "\n",
    "        # Ensure the length of the valid_str is within the desired range\n",
    "        if len(invalid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    # num_p = random.randint(0, max_length - len(invalid_str) - 2)\n",
    "    return (\n",
    "        # PADDING_TOKEN * num_p + \n",
    "        START_TOKEN\n",
    "        + invalid_str\n",
    "        + END_TOKEN\n",
    "        # + PADDING_TOKEN * ((max_length - len(invalid_str) - 2) - num_p)\n",
    "        + PADDING_TOKEN * ((max_length - len(invalid_str) - 2))\n",
    "    )\n",
    "\n",
    "\n",
    "# Generate dataset\n",
    "dataset = []\n",
    "num_samples = 50000  # Total number of samples\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    while True:\n",
    "        x = generate_valid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        x += PADDING_TOKEN * (OOD_MAX_LENGTH - MAX_LENGTH)\n",
    "        #print(x)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            #print('here')\n",
    "            continue\n",
    "        if (x, 1) not in dataset:\n",
    "            #print('Here2')\n",
    "            dataset.append((x, 1))\n",
    "            break\n",
    "\n",
    "\n",
    "# remove duplicates\n",
    "valid_dataset = list(set(dataset))\n",
    "dataset = []\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    while True:\n",
    "        x = generate_invalid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        x += PADDING_TOKEN * (OOD_MAX_LENGTH - MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 0) not in dataset:\n",
    "            dataset.append((x, 0))\n",
    "            break\n",
    "\n",
    "# Remove all duplicates\n",
    "invalid_dataset = list(set(dataset))[:len(valid_dataset)]\n",
    "print(f'len(valid_dataset): {len(valid_dataset)}')\n",
    "print(f'len(invalid_dataset): {len(invalid_dataset)}')\n",
    "\n",
    "split = len(valid_dataset) * 4 // 5\n",
    "train_dataset = valid_dataset[:split] + invalid_dataset[:split]\n",
    "test_dataset = valid_dataset[split:] + invalid_dataset[split:]\n",
    "\n",
    "num_ood_samples = 15000\n",
    "dataset = []\n",
    "for _ in tqdm(range(num_ood_samples)):\n",
    "    while True:\n",
    "        x = generate_valid_string(min_length=MAX_LENGTH + 2, max_length=OOD_MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 1) not in dataset:\n",
    "            dataset.append((x, 1))\n",
    "            break\n",
    "\n",
    "# remove duplicates\n",
    "ood_valid_dataset = list(set(dataset))\n",
    "dataset = []\n",
    "\n",
    "for _ in tqdm(range(num_ood_samples)):\n",
    "    while True:\n",
    "        x = generate_invalid_string(min_length=MAX_LENGTH + 2, max_length=OOD_MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 0) not in dataset:\n",
    "            dataset.append((x, 0))\n",
    "            break\n",
    "\n",
    "# Remove all duplicates\n",
    "ood_invalid_dataset = list(set(dataset))[:len(ood_valid_dataset)]\n",
    "print('len(ood_valid_dataset): ', len(ood_valid_dataset), 'len(ood_invalid_dataset): ', len(ood_invalid_dataset))\n",
    "\n",
    "ood_dataset = ood_valid_dataset + ood_invalid_dataset\n",
    "print('len(train_dataset): ', len(train_dataset))\n",
    "print('len(test_dataset): ',  len(test_dataset))\n",
    "print('len(ood_dataset): ',  len(ood_dataset))\n",
    "\n",
    "dir = f'/orion/u/yrichard/n/key_trials/test_aaaa_{MAX_LENGTH}_{OOD_MAX_LENGTH}'\n",
    "os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "# Write to file\n",
    "with open(dir + \"/train_dataset.txt\", \"w\") as f:\n",
    "    for data, label in train_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/test_dataset.txt\", \"w\") as f:\n",
    "    for data, label in test_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/ood_dataset.txt\", \"w\") as f:\n",
    "    for data, label in ood_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:39<00:00, 1250.45it/s]\n",
      "100%|██████████| 50000/50000 [00:38<00:00, 1299.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(valid_dataset): 50000\n",
      "len(invalid_dataset): 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:05<00:00, 2978.06it/s]\n",
      "100%|██████████| 15000/15000 [00:04<00:00, 3254.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ood_valid_dataset):  15000 len(ood_invalid_dataset):  15000\n",
      "len(train_dataset):  80000\n",
      "len(test_dataset):  20000\n",
      "len(ood_dataset):  30000\n",
      "/orion/u/yrichard/n/key_trials/test_NOa-b-c_200_400\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Define constants\n",
    "MAX_LENGTH = 200\n",
    "OOD_MAX_LENGTH = 400\n",
    "VALID_CHARACTERS = [\"s\", \"a\", \"b\", \"c\", 'd', 'f', 'g', 'x', 'y', 'z', \"e\", \"p\"]\n",
    "MAIN_CHARACTERS = [\"a\", \"b\", \"c\", 'd', 'f', 'g', 'x', 'y', 'z']\n",
    "START_TOKEN = \"s\"\n",
    "END_TOKEN = \"e\"\n",
    "PADDING_TOKEN = \"p\"\n",
    "VALID_RATIO = 0.5  # Half of the dataset should be valid a*b* strings\n",
    "\n",
    "\n",
    "# Function to generate valid a*b* strings\n",
    "def generate_valid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens\n",
    "    min_length = max(min_length, 2)\n",
    "    \n",
    "    while True:\n",
    "        # Generate the string with 'a's and 'b's while ensuring no three consecutive 'a's\n",
    "        valid_str = \"\"\n",
    "        valid_max = random.randint(0, max_length - 2)\n",
    "        while len(valid_str) < valid_max:\n",
    "            next_char = random.choice(['x', 'y', 'z'])\n",
    "            # if next_char == 'c' and valid_str.endswith('ab'):\n",
    "            #     next_char = random.choice(['a','b'])\n",
    "            valid_str += next_char\n",
    "            \n",
    "        \n",
    "        # Check if the length of the valid_str is within the desired range\n",
    "        if len(valid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    # num_p = random.randint(0, max_length - len(valid_str) - 2)\n",
    "    return (\n",
    "        # PADDING_TOKEN * num_p +\n",
    "        START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        # + PADDING_TOKEN * ((max_length - len(valid_str) - 2) - num_p)\n",
    "        + PADDING_TOKEN * ((max_length - len(valid_str) - 2))\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Function to generate invalid strings\n",
    "def generate_invalid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens    \n",
    "    while True:\n",
    "        # Generate the base string with random 'a's and 'b's\n",
    "        # num_invalids = int((max_length - min_length) * 0.05)\n",
    "        num_invalids = 3\n",
    "\n",
    "\n",
    "        base_str_length = random.randint(0, max_length - 2 - num_invalids*1)  # Account for START, END tokens, and at least three 'a's\n",
    "        base_str = ''.join(random.choice(['x', 'y', 'z']) for _ in range(base_str_length))\n",
    "        invalid_str = base_str\n",
    "        \n",
    "        # Insert 'aaa' at a random position\n",
    "        for i in range(num_invalids):\n",
    "            insert_pos = random.randint(0, len(invalid_str))\n",
    "            string = random.choice([\"a\", 'b', 'c'])\n",
    "            invalid_str = invalid_str[:insert_pos] + string + invalid_str[insert_pos:]\n",
    "            # if base_str_length % 2 == 0:\n",
    "            #     insert_pos = random.randint(0, len(invalid_str))\n",
    "            #     string = random.choice([\"a\"])\n",
    "            #     invalid_str = invalid_str[:insert_pos] + string + invalid_str[insert_pos:]\n",
    "\n",
    "        # Ensure the length of the valid_str is within the desired range\n",
    "        if len(invalid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    # num_p = random.randint(0, max_length - len(invalid_str) - 2)\n",
    "    return (\n",
    "        # PADDING_TOKEN * num_p + \n",
    "        START_TOKEN\n",
    "        + invalid_str\n",
    "        + END_TOKEN\n",
    "        # + PADDING_TOKEN * ((max_length - len(invalid_str) - 2) - num_p)\n",
    "        + PADDING_TOKEN * ((max_length - len(invalid_str) - 2))\n",
    "    )\n",
    "\n",
    "\n",
    "# Generate dataset\n",
    "dataset = []\n",
    "num_samples = 50000  # Total number of samples\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    while True:\n",
    "        x = generate_valid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        x += PADDING_TOKEN * (OOD_MAX_LENGTH - MAX_LENGTH)\n",
    "        #print(x)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            #print('here')\n",
    "            continue\n",
    "        if (x, 1) not in dataset:\n",
    "            #print('Here2')\n",
    "            dataset.append((x, 1))\n",
    "            break\n",
    "\n",
    "\n",
    "# remove duplicates\n",
    "valid_dataset = list(set(dataset))\n",
    "dataset = []\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    while True:\n",
    "        x = generate_invalid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        x += PADDING_TOKEN * (OOD_MAX_LENGTH - MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 0) not in dataset:\n",
    "            dataset.append((x, 0))\n",
    "            break\n",
    "\n",
    "# Remove all duplicates\n",
    "invalid_dataset = list(set(dataset))[:len(valid_dataset)]\n",
    "print(f'len(valid_dataset): {len(valid_dataset)}')\n",
    "print(f'len(invalid_dataset): {len(invalid_dataset)}')\n",
    "\n",
    "split = len(valid_dataset) * 4 // 5\n",
    "train_dataset = valid_dataset[:split] + invalid_dataset[:split]\n",
    "test_dataset = valid_dataset[split:] + invalid_dataset[split:]\n",
    "\n",
    "num_ood_samples = 15000\n",
    "dataset = []\n",
    "for _ in tqdm(range(num_ood_samples)):\n",
    "    while True:\n",
    "        x = generate_valid_string(min_length=MAX_LENGTH + 2, max_length=OOD_MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 1) not in dataset:\n",
    "            dataset.append((x, 1))\n",
    "            break\n",
    "\n",
    "# remove duplicates\n",
    "ood_valid_dataset = list(set(dataset))\n",
    "dataset = []\n",
    "\n",
    "for _ in tqdm(range(num_ood_samples)):\n",
    "    while True:\n",
    "        x = generate_invalid_string(min_length=MAX_LENGTH + 2, max_length=OOD_MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 0) not in dataset:\n",
    "            dataset.append((x, 0))\n",
    "            break\n",
    "\n",
    "# Remove all duplicates\n",
    "ood_invalid_dataset = list(set(dataset))[:len(ood_valid_dataset)]\n",
    "print('len(ood_valid_dataset): ', len(ood_valid_dataset), 'len(ood_invalid_dataset): ', len(ood_invalid_dataset))\n",
    "\n",
    "ood_dataset = ood_valid_dataset + ood_invalid_dataset\n",
    "print('len(train_dataset): ', len(train_dataset))\n",
    "print('len(test_dataset): ',  len(test_dataset))\n",
    "print('len(ood_dataset): ',  len(ood_dataset))\n",
    "\n",
    "dir = f'/orion/u/yrichard/n/key_trials/test_NOa-b-c_{MAX_LENGTH}_{OOD_MAX_LENGTH}'\n",
    "os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "# Write to file\n",
    "with open(dir + \"/train_dataset.txt\", \"w\") as f:\n",
    "    for data, label in train_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/test_dataset.txt\", \"w\") as f:\n",
    "    for data, label in test_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/ood_dataset.txt\", \"w\") as f:\n",
    "    for data, label in ood_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psacbacbccbbaabccaae\n",
      "pscabcbbbabceppppppp\n",
      "sbccacaccaaaabcbccep\n",
      "pppppppsabbabccbcbce\n",
      "psbcbacbcabcabbaaaep\n"
     ]
    }
   ],
   "source": [
    "def generate_invalid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens    \n",
    "    while True:\n",
    "        # Generate the base string with random 'a's and 'b's\n",
    "        base_str_length = random.randint(0, max_length - 5)  # Account for START, END tokens, and at least three 'a's\n",
    "        base_str = ''.join(random.choice(['a', 'b', 'c']) for _ in range(base_str_length))\n",
    "        \n",
    "        # Insert 'aaa' at a random position\n",
    "        insert_pos = random.randint(0, len(base_str))\n",
    "        valid_str = base_str[:insert_pos] + 'abc' + base_str[insert_pos:]\n",
    "        \n",
    "        # Ensure the length of the valid_str is within the desired range\n",
    "        if min_length - 2 <= len(valid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    num_p = random.randint(0, max_length - len(valid_str) - 2)\n",
    "    return (\n",
    "        PADDING_TOKEN * num_p\n",
    "        + START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        + PADDING_TOKEN * ((max_length - len(valid_str) - 2) - num_p)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    print(generate_invalid_string(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:11<00:00, 1333.59it/s]\n",
      "100%|██████████| 15000/15000 [00:10<00:00, 1474.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(valid_dataset): 15000\n",
      "len(invalid_dataset): 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:14<00:00, 1034.60it/s]\n",
      "100%|██████████| 15000/15000 [00:11<00:00, 1272.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ood_valid_dataset):  15000 len(ood_invalid_dataset):  15000\n",
      "len(train_dataset):  24000\n",
      "len(test_dataset):  6000\n",
      "len(ood_dataset):  30000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define constants\n",
    "MAX_LENGTH = 200\n",
    "OOD_MAX_LENGTH = 400\n",
    "VALID_CHARACTERS = [\"s\", \"a\", \"b\", \"c\", \"e\", \"p\"]\n",
    "MAIN_CHARACTERS = [\"a\", \"b\", \"c\"]\n",
    "START_TOKEN = \"s\"\n",
    "END_TOKEN = \"e\"\n",
    "PADDING_TOKEN = \"p\"\n",
    "VALID_RATIO = 0.5  # Half of the dataset should be valid a*b* strings\n",
    "\n",
    "\n",
    "# Function to generate valid a*b* strings\n",
    "def generate_valid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens\n",
    "    min_length = max(min_length, 2)\n",
    "    \n",
    "    while True:\n",
    "        # Generate the string with 'a's and 'b's while ensuring no three consecutive 'a's\n",
    "        valid_str = \"\"\n",
    "        valid_max = random.randint(0, max_length - 2)\n",
    "        while len(valid_str) < valid_max:\n",
    "            next_char = random.choice(['a', 'b', 'c'])\n",
    "            if next_char == 'c' and valid_str.endswith('ab'):\n",
    "                next_char = random.choice(['a', 'b'])\n",
    "            valid_str += next_char\n",
    "            \n",
    "        \n",
    "        # Check if the length of the valid_str is within the desired range\n",
    "        if len(valid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    num_p = random.randint(0, max_length - len(valid_str) - 2)\n",
    "    return (\n",
    "        PADDING_TOKEN * num_p\n",
    "        + START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        + PADDING_TOKEN * ((max_length - len(valid_str) - 2) - num_p)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Function to generate invalid strings\n",
    "def generate_invalid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens    \n",
    "    while True:\n",
    "        # Generate the base string with random 'a's and 'b's\n",
    "        base_str_length = random.randint(0, max_length - 5)  # Account for START, END tokens, and at least three 'a's\n",
    "        base_str = ''.join(random.choice(['a', 'b', 'c']) for _ in range(base_str_length))\n",
    "        \n",
    "        # Insert 'aaa' at a random position\n",
    "        insert_pos = random.randint(0, len(base_str))\n",
    "        valid_str = base_str[:insert_pos] + 'abc' + base_str[insert_pos:]\n",
    "        \n",
    "        # Ensure the length of the valid_str is within the desired range\n",
    "        if len(valid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    num_p = random.randint(0, max_length - len(valid_str) - 2)\n",
    "    return (\n",
    "        PADDING_TOKEN * num_p\n",
    "        + START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        + PADDING_TOKEN * ((max_length - len(valid_str) - 2) - num_p)\n",
    "    )\n",
    "\n",
    "\n",
    "# Generate dataset\n",
    "dataset = []\n",
    "num_samples = 15000  # Total number of samples\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    while True:\n",
    "        x = generate_valid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        x += PADDING_TOKEN * (OOD_MAX_LENGTH - MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 1) not in dataset:\n",
    "            dataset.append((x, 1))\n",
    "            break\n",
    "\n",
    "\n",
    "# remove duplicates\n",
    "valid_dataset = list(set(dataset))\n",
    "dataset = []\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    while True:\n",
    "        x = generate_invalid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        x += PADDING_TOKEN * (OOD_MAX_LENGTH - MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 0) not in dataset:\n",
    "            dataset.append((x, 0))\n",
    "            break\n",
    "\n",
    "# Remove all duplicates\n",
    "invalid_dataset = list(set(dataset))[:len(valid_dataset)]\n",
    "print(f'len(valid_dataset): {len(valid_dataset)}')\n",
    "print(f'len(invalid_dataset): {len(invalid_dataset)}')\n",
    "\n",
    "split = len(valid_dataset) * 4 // 5\n",
    "train_dataset = valid_dataset[:split] + invalid_dataset[:split]\n",
    "test_dataset = valid_dataset[split:] + invalid_dataset[split:]\n",
    "\n",
    "num_ood_samples = 15000\n",
    "dataset = []\n",
    "for _ in tqdm(range(num_ood_samples)):\n",
    "    while True:\n",
    "        x = generate_valid_string(min_length=MAX_LENGTH + 2, max_length=OOD_MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 1) not in dataset:\n",
    "            dataset.append((x, 1))\n",
    "            break\n",
    "\n",
    "# remove duplicates\n",
    "ood_valid_dataset = list(set(dataset))\n",
    "dataset = []\n",
    "\n",
    "for _ in tqdm(range(num_ood_samples)):\n",
    "    while True:\n",
    "        x = generate_invalid_string(min_length=MAX_LENGTH + 2, max_length=OOD_MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 0) not in dataset:\n",
    "            dataset.append((x, 0))\n",
    "            break\n",
    "\n",
    "# Remove all duplicates\n",
    "ood_invalid_dataset = list(set(dataset))[:len(ood_valid_dataset)]\n",
    "print('len(ood_valid_dataset): ', len(ood_valid_dataset), 'len(ood_invalid_dataset): ', len(ood_invalid_dataset))\n",
    "\n",
    "ood_dataset = ood_valid_dataset + ood_invalid_dataset\n",
    "print('len(train_dataset): ', len(train_dataset))\n",
    "print('len(test_dataset): ',  len(test_dataset))\n",
    "print('len(ood_dataset): ',  len(ood_dataset))\n",
    "\n",
    "dir = '/orion/u/yrichard/n/key_trials/test_abc_200_400_padded'\n",
    "\n",
    "\n",
    "# Write to file\n",
    "with open(dir + \"/train_dataset.txt\", \"w\") as f:\n",
    "    for data, label in train_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/test_dataset.txt\", \"w\") as f:\n",
    "    for data, label in test_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/ood_dataset.txt\", \"w\") as f:\n",
    "    for data, label in ood_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:09<00:00, 1578.73it/s]\n",
      "100%|██████████| 15000/15000 [00:07<00:00, 1949.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(valid_dataset): 15000\n",
      "len(invalid_dataset): 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:09<00:00, 1561.91it/s]\n",
      "100%|██████████| 15000/15000 [00:08<00:00, 1797.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ood_valid_dataset):  15000 len(ood_invalid_dataset):  15000\n",
      "len(train_dataset):  24000\n",
      "len(test_dataset):  6000\n",
      "len(ood_dataset):  30000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define constants\n",
    "MAX_LENGTH = 200\n",
    "OOD_MAX_LENGTH = 400\n",
    "VALID_CHARACTERS = [\"s\", \"a\", \"b\", \"c\", \"e\", \"p\"]\n",
    "MAIN_CHARACTERS = [\"a\", \"b\", \"c\"]\n",
    "START_TOKEN = \"s\"\n",
    "END_TOKEN = \"e\"\n",
    "PADDING_TOKEN = \"p\"\n",
    "VALID_RATIO = 0.5  # Half of the dataset should be valid a*b* strings\n",
    "\n",
    "\n",
    "# Function to generate valid a*b* strings\n",
    "def generate_valid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens\n",
    "    min_length = max(min_length, 2)\n",
    "    \n",
    "    while True:\n",
    "        # Generate the string with 'a's and 'b's while ensuring no three consecutive 'a's\n",
    "        valid_str = \"\"\n",
    "        valid_max = random.randint(0, max_length - 2)\n",
    "        while len(valid_str) < valid_max:\n",
    "            next_char = random.choice(['a', 'b', 'c'])\n",
    "            if next_char == 'c' and valid_str.endswith('ab'):\n",
    "                next_char = random.choice(['a', 'b'])\n",
    "            valid_str += next_char\n",
    "            \n",
    "        \n",
    "        # Check if the length of the valid_str is within the desired range\n",
    "        if len(valid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    # num_p = random.randint(0, max_length - len(valid_str) - 2)\n",
    "    return (\n",
    "        #PADDING_TOKEN * num_p\n",
    "        START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        + PADDING_TOKEN * ((max_length - len(valid_str) - 2))\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Function to generate invalid strings\n",
    "def generate_invalid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens    \n",
    "    while True:\n",
    "        # Generate the base string with random 'a's and 'b's\n",
    "        base_str_length = random.randint(0, max_length - 5)  # Account for START, END tokens, and at least three 'a's\n",
    "        base_str = ''.join(random.choice(['a', 'b', 'c']) for _ in range(base_str_length))\n",
    "        \n",
    "        # Insert 'aaa' at a random position\n",
    "        insert_pos = random.randint(0, len(base_str))\n",
    "        valid_str = base_str[:insert_pos] + 'abc' + base_str[insert_pos:]\n",
    "        \n",
    "        # Ensure the length of the valid_str is within the desired range\n",
    "        if len(valid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    # num_p = random.randint(0, max_length - len(valid_str) - 2)\n",
    "    return (\n",
    "        START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        + PADDING_TOKEN * ((max_length - len(valid_str) - 2))\n",
    "    )\n",
    "\n",
    "\n",
    "# Generate dataset\n",
    "dataset = []\n",
    "num_samples = 15000  # Total number of samples\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    while True:\n",
    "        x = generate_valid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        x += PADDING_TOKEN * (OOD_MAX_LENGTH - MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 1) not in dataset:\n",
    "            dataset.append((x, 1))\n",
    "            break\n",
    "\n",
    "\n",
    "# remove duplicates\n",
    "valid_dataset = list(set(dataset))\n",
    "dataset = []\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    while True:\n",
    "        x = generate_invalid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        x += PADDING_TOKEN * (OOD_MAX_LENGTH - MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 0) not in dataset:\n",
    "            dataset.append((x, 0))\n",
    "            break\n",
    "\n",
    "# Remove all duplicates\n",
    "invalid_dataset = list(set(dataset))[:len(valid_dataset)]\n",
    "print(f'len(valid_dataset): {len(valid_dataset)}')\n",
    "print(f'len(invalid_dataset): {len(invalid_dataset)}')\n",
    "\n",
    "split = len(valid_dataset) * 4 // 5\n",
    "train_dataset = valid_dataset[:split] + invalid_dataset[:split]\n",
    "test_dataset = valid_dataset[split:] + invalid_dataset[split:]\n",
    "\n",
    "num_ood_samples = 15000\n",
    "dataset = []\n",
    "for _ in tqdm(range(num_ood_samples)):\n",
    "    while True:\n",
    "        x = generate_valid_string(min_length=MAX_LENGTH + 2, max_length=OOD_MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 1) not in dataset:\n",
    "            dataset.append((x, 1))\n",
    "            break\n",
    "\n",
    "# remove duplicates\n",
    "ood_valid_dataset = list(set(dataset))\n",
    "dataset = []\n",
    "\n",
    "for _ in tqdm(range(num_ood_samples)):\n",
    "    while True:\n",
    "        x = generate_invalid_string(min_length=MAX_LENGTH + 2, max_length=OOD_MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 0) not in dataset:\n",
    "            dataset.append((x, 0))\n",
    "            break\n",
    "\n",
    "# Remove all duplicates\n",
    "ood_invalid_dataset = list(set(dataset))[:len(ood_valid_dataset)]\n",
    "print('len(ood_valid_dataset): ', len(ood_valid_dataset), 'len(ood_invalid_dataset): ', len(ood_invalid_dataset))\n",
    "\n",
    "ood_dataset = ood_valid_dataset + ood_invalid_dataset\n",
    "print('len(train_dataset): ', len(train_dataset))\n",
    "print('len(test_dataset): ',  len(test_dataset))\n",
    "print('len(ood_dataset): ',  len(ood_dataset))\n",
    "\n",
    "dir = '/orion/u/yrichard/n/key_trials/test_abc_200_400'\n",
    "\n",
    "\n",
    "# Write to file\n",
    "with open(dir + \"/train_dataset.txt\", \"w\") as f:\n",
    "    for data, label in train_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/test_dataset.txt\", \"w\") as f:\n",
    "    for data, label in test_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/ood_dataset.txt\", \"w\") as f:\n",
    "    for data, label in ood_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbbabbaabbabbaaaaaae\n",
      "saaaaaaaaaaaababbbae\n",
      "saaaabbbbaabbabbaaae\n",
      "sbaabbaaaaaaaaabbabe\n",
      "sbbabaaaaaaabbbaaabe\n"
     ]
    }
   ],
   "source": [
    "def generate_invalid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens    \n",
    "    while True:\n",
    "        # Generate the base string with random 'a's and 'b's\n",
    "        base_str_length = max_length - 6  # Account for START, END tokens, and at least three 'a's\n",
    "        base_str = ''.join(random.choice(['a', 'b']) for _ in range(base_str_length))\n",
    "        \n",
    "        # Insert 'aaa' at a random position\n",
    "        insert_pos = random.randint(0, len(base_str))\n",
    "        valid_str = base_str[:insert_pos] + 'aaaa' + base_str[insert_pos:]\n",
    "        \n",
    "        # Ensure the length of the valid_str is within the desired range\n",
    "        if min_length - 2 <= len(valid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    num_p = random.randint(0, max_length - len(valid_str) - 2)\n",
    "    return (\n",
    "        PADDING_TOKEN * num_p\n",
    "        + START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        + PADDING_TOKEN * ((max_length - len(valid_str) - 2) - num_p)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    print(generate_invalid_string(min_length=10, max_length=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:09<00:00, 1599.80it/s]\n",
      "100%|██████████| 15000/15000 [00:07<00:00, 1875.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(valid_dataset): 15000\n",
      "len(invalid_dataset): 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:15<00:00, 997.83it/s]\n",
      "100%|██████████| 15000/15000 [00:12<00:00, 1230.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ood_valid_dataset):  15000 len(ood_invalid_dataset):  15000\n",
      "len(train_dataset):  24000\n",
      "len(test_dataset):  6000\n",
      "len(ood_dataset):  30000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define constants\n",
    "MAX_LENGTH = 200\n",
    "OOD_MAX_LENGTH = 400\n",
    "VALID_CHARACTERS = [\"s\", \"a\", \"b\", \"e\", \"p\"]\n",
    "MAIN_CHARACTERS = [\"a\", \"b\"]\n",
    "START_TOKEN = \"s\"\n",
    "END_TOKEN = \"e\"\n",
    "PADDING_TOKEN = \"p\"\n",
    "VALID_RATIO = 0.5  # Half of the dataset should be valid a*b* strings\n",
    "\n",
    "\n",
    "# Function to generate valid a*b* strings\n",
    "def generate_valid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens\n",
    "    min_length = max(min_length, 2)\n",
    "    \n",
    "    while True:\n",
    "        # Generate the string with 'a's and 'b's while ensuring no three consecutive 'a's\n",
    "        valid_str = \"\"\n",
    "        valid_length = random.randint(0, max_length - 2)\n",
    "        while len(valid_str) < valid_length:\n",
    "            next_char = random.choice(['a', 'b'])\n",
    "            if next_char == 'a' and valid_str.endswith('aaa'):\n",
    "                next_char = 'b'\n",
    "            valid_str += next_char\n",
    "            \n",
    "        \n",
    "        # Check if the length of the valid_str is within the desired range\n",
    "        if len(valid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    num_p = random.randint(0, max_length - len(valid_str) - 2)\n",
    "    return (\n",
    "        PADDING_TOKEN * num_p\n",
    "        + START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        + PADDING_TOKEN * ((max_length - len(valid_str) - 2) - num_p)\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to generate invalid strings\n",
    "def generate_invalid_string(min_length=0, max_length=MAX_LENGTH):\n",
    "    # Ensure the minimum length accounts for START and END tokens    \n",
    "    while True:\n",
    "        # Generate the base string with random 'a's and 'b's\n",
    "        base_str_length = random.randint(0, max_length - 6)  # Account for START, END tokens, and at least three 'a's\n",
    "        base_str = ''.join(random.choice(['a', 'b']) for _ in range(base_str_length))\n",
    "        \n",
    "        # Insert 'aaa' at a random position\n",
    "        insert_pos = random.randint(0, len(base_str))\n",
    "        valid_str = base_str[:insert_pos] + 'aaaa' + base_str[insert_pos:]\n",
    "        \n",
    "        # Ensure the length of the valid_str is within the desired range\n",
    "        if len(valid_str) <= max_length - 2:\n",
    "            break\n",
    "    \n",
    "    # Calculate the padding needed\n",
    "    num_p = random.randint(0, max_length - len(valid_str) - 2)\n",
    "    return (\n",
    "        PADDING_TOKEN * num_p\n",
    "        + START_TOKEN\n",
    "        + valid_str\n",
    "        + END_TOKEN\n",
    "        + PADDING_TOKEN * ((max_length - len(valid_str) - 2) - num_p)\n",
    "    )\n",
    "\n",
    "\n",
    "# Generate dataset\n",
    "dataset = []\n",
    "num_samples = 15000  # Total number of samples\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    while True:\n",
    "        x = generate_valid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        x += PADDING_TOKEN * (OOD_MAX_LENGTH - MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 1) not in dataset:\n",
    "            dataset.append((x, 1))\n",
    "            break\n",
    "\n",
    "\n",
    "# remove duplicates\n",
    "valid_dataset = list(set(dataset))\n",
    "dataset = []\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    while True:\n",
    "        x = generate_invalid_string()\n",
    "        if not (len(x) == MAX_LENGTH):\n",
    "            continue\n",
    "        x += PADDING_TOKEN * (OOD_MAX_LENGTH - MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 0) not in dataset:\n",
    "            dataset.append((x, 0))\n",
    "            break\n",
    "\n",
    "# Remove all duplicates\n",
    "invalid_dataset = list(set(dataset))[:len(valid_dataset)]\n",
    "print(f'len(valid_dataset): {len(valid_dataset)}')\n",
    "print(f'len(invalid_dataset): {len(invalid_dataset)}')\n",
    "\n",
    "split = len(valid_dataset) * 4 // 5\n",
    "train_dataset = valid_dataset[:split] + invalid_dataset[:split]\n",
    "test_dataset = valid_dataset[split:] + invalid_dataset[split:]\n",
    "\n",
    "num_ood_samples = 15000\n",
    "dataset = []\n",
    "for _ in tqdm(range(num_ood_samples)):\n",
    "    while True:\n",
    "        x = generate_valid_string(min_length=MAX_LENGTH + 2, max_length=OOD_MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 1) not in dataset:\n",
    "            dataset.append((x, 1))\n",
    "            break\n",
    "\n",
    "# remove duplicates\n",
    "ood_valid_dataset = list(set(dataset))\n",
    "dataset = []\n",
    "\n",
    "for _ in tqdm(range(num_ood_samples)):\n",
    "    while True:\n",
    "        x = generate_invalid_string(min_length=MAX_LENGTH + 2, max_length=OOD_MAX_LENGTH)\n",
    "        if not (len(x) == OOD_MAX_LENGTH):\n",
    "            continue\n",
    "        if (x, 0) not in dataset:\n",
    "            dataset.append((x, 0))\n",
    "            break\n",
    "\n",
    "# Remove all duplicates\n",
    "ood_invalid_dataset = list(set(dataset))[:len(ood_valid_dataset)]\n",
    "print('len(ood_valid_dataset): ', len(ood_valid_dataset), 'len(ood_invalid_dataset): ', len(ood_invalid_dataset))\n",
    "\n",
    "ood_dataset = ood_valid_dataset + ood_invalid_dataset\n",
    "print('len(train_dataset): ', len(train_dataset))\n",
    "print('len(test_dataset): ',  len(test_dataset))\n",
    "print('len(ood_dataset): ',  len(ood_dataset))\n",
    "\n",
    "dir = '/orion/u/yrichard/n/key_trials/test_aaaa_200_400_padded'\n",
    "\n",
    "\n",
    "# Write to file\n",
    "with open(dir + \"/train_dataset.txt\", \"w\") as f:\n",
    "    for data, label in train_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/test_dataset.txt\", \"w\") as f:\n",
    "    for data, label in test_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/ood_dataset.txt\", \"w\") as f:\n",
    "    for data, label in ood_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/orion/u/yrichard/n/key_trials/test_aaa_200_400'\n",
    "\n",
    "\n",
    "# Write to file\n",
    "with open(dir + \"/train_dataset.txt\", \"w\") as f:\n",
    "    for data, label in train_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/test_dataset.txt\", \"w\") as f:\n",
    "    for data, label in test_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")\n",
    "\n",
    "with open(dir + \"/ood_dataset.txt\", \"w\") as f:\n",
    "    for data, label in ood_dataset:\n",
    "        f.write(f\"{data} {label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tasksolver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
